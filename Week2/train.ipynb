{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 引用需要的函式庫","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader, random_split\n\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-08-10T04:55:39.917253Z","iopub.execute_input":"2024-08-10T04:55:39.917616Z","iopub.status.idle":"2024-08-10T04:55:43.444221Z","shell.execute_reply.started":"2024-08-10T04:55:39.917587Z","shell.execute_reply":"2024-08-10T04:55:43.443411Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# 自定義資料集\n讀取CSV檔中的MNIST資料集，每一列代表一個圖片的類別與784個畫素值  \n將784個畫素重新排列為28*28的二維陣列，並轉換為Pillow image便於後續的資料前處理  ","metadata":{}},{"cell_type":"code","source":"class MNISTDataset(Dataset):\n    def __init__(self, csv_file, transform=None):\n        self.data_frame = pd.read_csv(csv_file) # read data from csv file as a pandas dataframe\n        self.transform = transform # initial transfrom\n\n    def __len__(self):\n        return len(self.data_frame)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        # transfer data from list to Pillow image\n        image = Image.fromarray(self.data_frame.iloc[idx, 1:].values.reshape(28, 28).astype(np.uint8))\n        \n        label = int(self.data_frame.iloc[idx, 0])\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-08-10T04:55:43.445654Z","iopub.execute_input":"2024-08-10T04:55:43.446070Z","iopub.status.idle":"2024-08-10T04:55:43.452965Z","shell.execute_reply.started":"2024-08-10T04:55:43.446044Z","shell.execute_reply":"2024-08-10T04:55:43.452137Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 資料前處理\n定義適用於訓練集與測試集的transform分別進行各自的資料前處理流程","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=3),\n#     transforms.RandomResizedCrop(size=(224, 224), scale=(0.5, 1.0)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.RandomRotation(degrees=90),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4850, 0.4560, 0.4060], std=[0.2290, 0.2240, 0.2250])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=3),\n#     transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4850, 0.4560, 0.4060], std=[0.2290, 0.2240, 0.2250])\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-10T04:55:43.454178Z","iopub.execute_input":"2024-08-10T04:55:43.454513Z","iopub.status.idle":"2024-08-10T04:55:43.465231Z","shell.execute_reply.started":"2024-08-10T04:55:43.454482Z","shell.execute_reply":"2024-08-10T04:55:43.464481Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# 建立訓練集、驗證集、測試集\n由於MNIST資料集未提供獨立的驗證集，因此將一半的測試集拆分出來做為驗證集  \n驗證集可以監控模型是否overfitting，同時作為保存最佳模型的標準","metadata":{}},{"cell_type":"code","source":"train_path = '/kaggle/input/fashionmnist/fashion-mnist_train.csv'\ntest_path = '/kaggle/input/fashionmnist/fashion-mnist_test.csv'\n\ntrain_data = MNISTDataset(csv_file=train_path, transform=train_transform)\ntest_data = MNISTDataset(csv_file=test_path, transform=test_transform)\ntestLen = int(len(test_data) * 0.5)\nvalLen = len(test_data) - testLen\ntest_data, val_data = random_split(test_data, [testLen, valLen])","metadata":{"execution":{"iopub.status.busy":"2024-08-10T04:55:43.467081Z","iopub.execute_input":"2024-08-10T04:55:43.467363Z","iopub.status.idle":"2024-08-10T04:55:50.405351Z","shell.execute_reply.started":"2024-08-10T04:55:43.467341Z","shell.execute_reply":"2024-08-10T04:55:50.404399Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# image, label = train_data.__getitem__(0)\n# plt.imshow(image)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T04:55:50.406727Z","iopub.execute_input":"2024-08-10T04:55:50.407421Z","iopub.status.idle":"2024-08-10T04:55:50.411281Z","shell.execute_reply.started":"2024-08-10T04:55:50.407386Z","shell.execute_reply":"2024-08-10T04:55:50.410352Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# 建立DataLoader\n可決定batch size、以及資料集載入時是否打亂","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=128, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=128, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T04:55:50.412403Z","iopub.execute_input":"2024-08-10T04:55:50.412670Z","iopub.status.idle":"2024-08-10T04:55:50.422408Z","shell.execute_reply.started":"2024-08-10T04:55:50.412647Z","shell.execute_reply":"2024-08-10T04:55:50.421570Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# 訓練用硬體\n決定使用GPU或是CPU進行訓練  \n範例優先選用GPU，若GPU不可用則使用CPU","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T04:55:50.423573Z","iopub.execute_input":"2024-08-10T04:55:50.423826Z","iopub.status.idle":"2024-08-10T04:55:50.465742Z","shell.execute_reply.started":"2024-08-10T04:55:50.423804Z","shell.execute_reply":"2024-08-10T04:55:50.464765Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 選擇Model、Loss Function以及Optimizer\n修改最後的全連階層使其適應資料集的類別數量  \n設定完成後會將model移至GPU/CPU","metadata":{}},{"cell_type":"code","source":"model = models.resnet18(weights=None)\nmodel.fc = nn.Linear(model.fc.in_features, 10)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), weight_decay=0.01, lr=0.001)\n\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-10T04:55:50.466778Z","iopub.execute_input":"2024-08-10T04:55:50.467051Z","iopub.status.idle":"2024-08-10T04:55:50.845900Z","shell.execute_reply.started":"2024-08-10T04:55:50.467027Z","shell.execute_reply":"2024-08-10T04:55:50.845047Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# 訓練模型\n訓練過程會走訪資料集共20輪\n每一輪都會計算training與validation的loss與accuracy  \n以validation accuracy為標準保存最佳的模型參數","metadata":{}},{"cell_type":"code","source":"num_epochs = 20\nbest_accuracy = 0.0\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * inputs.size(0)\n\n        _, predicted = torch.max(outputs, 1)\n        total_train += labels.size(0)\n        correct_train += (predicted == labels).sum().item()\n\n    train_loss = running_loss / len(train_loader.dataset)\n    train_accuracy = correct_train / total_train\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n\n    model.eval()\n    running_val_loss = 0.0\n    correct_val = 0\n    total_val = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_val_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            total_val += labels.size(0)\n            correct_val += (predicted == labels).sum().item()\n\n        val_loss = running_val_loss / len(val_loader.dataset)\n        val_accuracy = correct_val / total_val\n\n        if val_accuracy > best_accuracy:\n            # Save model weights\n            torch.save(model.state_dict(), 'best_model.pth')\n            best_accuracy = val_accuracy\n\n        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-10T04:55:50.846916Z","iopub.execute_input":"2024-08-10T04:55:50.847190Z","iopub.status.idle":"2024-08-10T05:20:10.724963Z","shell.execute_reply.started":"2024-08-10T04:55:50.847167Z","shell.execute_reply":"2024-08-10T05:20:10.723994Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 1/20, Training Loss: 0.9213, Training Accuracy: 0.6580\nValidation Loss: 0.7517, Validation Accuracy: 0.7182\nEpoch 2/20, Training Loss: 0.7072, Training Accuracy: 0.7388\nValidation Loss: 0.6781, Validation Accuracy: 0.7480\nEpoch 3/20, Training Loss: 0.6157, Training Accuracy: 0.7735\nValidation Loss: 0.5167, Validation Accuracy: 0.8176\nEpoch 4/20, Training Loss: 0.5661, Training Accuracy: 0.7920\nValidation Loss: 0.5129, Validation Accuracy: 0.8134\nEpoch 5/20, Training Loss: 0.5278, Training Accuracy: 0.8062\nValidation Loss: 0.5241, Validation Accuracy: 0.8052\nEpoch 6/20, Training Loss: 0.5054, Training Accuracy: 0.8151\nValidation Loss: 0.5207, Validation Accuracy: 0.8114\nEpoch 7/20, Training Loss: 0.4823, Training Accuracy: 0.8229\nValidation Loss: 0.4342, Validation Accuracy: 0.8400\nEpoch 8/20, Training Loss: 0.4639, Training Accuracy: 0.8288\nValidation Loss: 0.4444, Validation Accuracy: 0.8358\nEpoch 9/20, Training Loss: 0.4479, Training Accuracy: 0.8346\nValidation Loss: 0.4167, Validation Accuracy: 0.8452\nEpoch 10/20, Training Loss: 0.4342, Training Accuracy: 0.8391\nValidation Loss: 0.4579, Validation Accuracy: 0.8366\nEpoch 11/20, Training Loss: 0.4204, Training Accuracy: 0.8443\nValidation Loss: 0.4039, Validation Accuracy: 0.8508\nEpoch 12/20, Training Loss: 0.4079, Training Accuracy: 0.8487\nValidation Loss: 0.3840, Validation Accuracy: 0.8594\nEpoch 13/20, Training Loss: 0.4044, Training Accuracy: 0.8508\nValidation Loss: 0.3964, Validation Accuracy: 0.8534\nEpoch 14/20, Training Loss: 0.3927, Training Accuracy: 0.8557\nValidation Loss: 0.3829, Validation Accuracy: 0.8580\nEpoch 15/20, Training Loss: 0.3874, Training Accuracy: 0.8552\nValidation Loss: 0.3753, Validation Accuracy: 0.8604\nEpoch 16/20, Training Loss: 0.3785, Training Accuracy: 0.8591\nValidation Loss: 0.3716, Validation Accuracy: 0.8656\nEpoch 17/20, Training Loss: 0.3724, Training Accuracy: 0.8621\nValidation Loss: 0.3384, Validation Accuracy: 0.8712\nEpoch 18/20, Training Loss: 0.3677, Training Accuracy: 0.8623\nValidation Loss: 0.3554, Validation Accuracy: 0.8656\nEpoch 19/20, Training Loss: 0.3608, Training Accuracy: 0.8666\nValidation Loss: 0.3521, Validation Accuracy: 0.8720\nEpoch 20/20, Training Loss: 0.3555, Training Accuracy: 0.8673\nValidation Loss: 0.3340, Validation Accuracy: 0.8796\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 測試模型\n載入最佳的模型參數  \n在testing set測試模型並計算loss與accuracy","metadata":{}},{"cell_type":"code","source":"model.load_state_dict(torch.load('best_model.pth'))\n\nmodel.eval()  # 设置模型为评估模式\nrunning_test_loss = 0.0\ncorrect_test = 0\ntotal_test = 0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        running_test_loss += loss.item() * inputs.size(0)\n        _, predicted = torch.max(outputs, 1)\n        total_test += labels.size(0)\n        correct_test += (predicted == labels).sum().item()\n\ntest_loss = running_test_loss / len(test_loader.dataset)\ntest_accuracy = correct_test / total_test\n\nprint(f'Testing Loss: {test_loss:.4f}, Testing Accuracy: {test_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-08-10T05:20:10.728039Z","iopub.execute_input":"2024-08-10T05:20:10.728385Z","iopub.status.idle":"2024-08-10T05:20:13.662256Z","shell.execute_reply.started":"2024-08-10T05:20:10.728359Z","shell.execute_reply":"2024-08-10T05:20:13.661337Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Testing Loss: 0.3195, Testing Accuracy: 0.8786\n","output_type":"stream"}]}]}